# ğŸ§  Toxicity Checker App

Um aplicativo em **React Native** que utiliza **TensorFlow.js** para detectar toxicidade em textos (insulto, ameaÃ§a, ofensa, etc.).  

ğŸ“± O usuÃ¡rio digita uma frase e o app retorna se hÃ¡ algum tipo de agressividade ou se o texto Ã© seguro.

---

## ğŸš€ Funcionalidades

- Entrada de texto pelo usuÃ¡rio.  
- ClassificaÃ§Ã£o de toxicidade com modelo do **TensorFlow.js**.  
- Retorna a categoria mais provÃ¡vel (ex.: *insult*, *threat*, *identity attack*).  
- Se nÃ£o houver nada relevante, exibe **"no toxicy"**.  
- HistÃ³rico simples dos textos digitados.  

---

## ğŸ“¸ Screenshots

| Tela inicial | Texto comum | Sem toxicidade |
|--------------|-------------|----------------|
| ![s1](./docs/screenshots/1.jpg) | ![s2](./docs/screenshots/2.jpg) | ![s3](./docs/screenshots/3.jpg) |

| Texto ofensivo | Exemplo de insulto |
|----------------|--------------------|
| ![s4](./docs/screenshots/4.jpg) | ![s5](./docs/screenshots/5.jpg) |

---

## ğŸ› ï¸ Tecnologias usadas

- [React Native](https://reactnative.dev/)  
- [TensorFlow.js](https://www.tensorflow.org/js)  
- [Expo (opcional)]  

---

## ğŸ“‚ Estrutura do Projeto

